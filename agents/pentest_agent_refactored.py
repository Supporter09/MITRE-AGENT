from dotenv import load_dotenv

load_dotenv()

import os
import json
import subprocess
import re
import uuid
import logging
from typing import TypedDict, Annotated, List, Dict, Optional, Literal, Any
import datetime
import sys

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from langgraph.graph import StateGraph, END, MessagesState
from langgraph.graph.message import add_messages
from langchain_core.messages import (
    HumanMessage,
    AIMessage,
    SystemMessage,
    BaseMessage,
    ToolCall,  # Corrected: Was ToolCall from langchain_core.messages.tool
    ToolMessage,  # <-- Add this import
)

# from langchain_core.messages.tool import ToolCall # This was the original, but ToolCall is also in langchain_core.messages
from pydantic import BaseModel, Field
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI  # Or your preferred LLM provider
from langchain_ollama import ChatOllama  # Ollama LLM provider
from mem0 import MemoryClient
from qdrant_client import QdrantClient, models as qdrant_models
from services.ollama_service import get_embedding


# --- Setup Logging ---
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# --- Configuration ---
# Set these environment variables
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# MEM0_API_KEY = os.getenv("MEM0_API_KEY")
# QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
# QDRANT_API_KEY = os.getenv("QDRANT_API_KEY") # Optional

# --- Constants ---
PENTEST_MEM0_COLLECTION = "web_pentest_knowledge_base"
QDRANT_COLLECTION_VULNS = "pentest_vulnerabilities"
QDRANT_COLLECTION_PAYLOADS = "pentest_payloads"
QDRANT_COLLECTION_REPORTS = "pentest_past_reports"

# --- Memory Management (Adapted from your provided examples) ---


class PentestMemoryClient:
    def __init__(self, collection_name: str = "web_pentest_memories"):
        self.collection = collection_name
        if os.environ.get("MEM0_API_KEY") is not None:
            os.environ["MEM0_API_KEY"] = os.environ.get("MEM0_API_KEY")
        if os.environ.get("OPENAI_API_KEY") is not None:
            os.environ["OPENAI_API_KEY"] = os.environ.get("OPENAI_API_KEY")
        self.api_key = os.getenv("MEM0_API_KEY")
        if self.api_key:
            self.client = MemoryClient()
        else:
            self.client = None
            logger.warning(
                "MEM0_API_KEY not set. PentestMemoryClient will not persist memory."
            )

    def add(self, messages: list, user_id: str, session_id: str, metadata: dict = None):
        if not self.client:
            logger.warning(
                "Skipping add memory: Mem0 client not available or API key missing."
            )
            return "Memory not saved (client/key unavailable)."

        # Check if messages is already in the new format
        # The original add method expects a list of dicts with 'role' and 'content'
        # If messages are BaseMessage objects, they need to be formatted.
        formatted_messages = []
        if (
            messages
            and isinstance(messages[0], dict)
            and "role" in messages[0]
            and "content" in messages[0]
        ):
            formatted_messages = messages  # Already in correct format
        else:  # Assume list of BaseMessage objects
            for msg in messages:
                if hasattr(msg, "content"):
                    role = (
                        "assistant"
                        if isinstance(msg, AIMessage)
                        else "system" if isinstance(msg, SystemMessage) else "user"
                    )
                    formatted_messages.append({"role": role, "content": msg.content})

        if not formatted_messages:
            logger.info("No messages to add to memory.")
            return "No messages to save."
        try:
            # The mem0 client.add now expects `messages` directly, not `data`
            response = self.client.add(
                messages=formatted_messages,  # Use the formatted messages
                user_id=user_id,
                session_id=session_id,
                collection=self.collection,
                version="v2",  # Ensure this is compatible; original had 'version' here
                metadata=metadata or {},
            )
            logger.info(
                f"Memory added successfully via v2 format. Response: {response}"
            )
            return "Memory saved (v2)."
        except Exception as e:
            logger.error(
                f"Error adding memory (v2) for user {user_id}, session {session_id}: {e}"
            )
            return f"Error saving memory (v2): {e}"

    def search(self, query: str, user_id: str, session_id: str, limit: int = 3):
        if not self.client:
            logger.warning(
                "Skipping search memory: Mem0 client not available or API key missing."
            )
            return None
        try:
            results = self.client.search(
                query=query,
                user_id=user_id,
                session_id=session_id,
                collection=self.collection,
                limit=limit,
            )
            logger.info(f"Memory search raw results: {results}")
            if results:
                return "\n".join([m.get("memory", "") for m in results])
            else:
                logger.info("No relevant memories found.")
                return None
        except Exception as e:
            logger.error(
                f"Error searching memory for user {user_id}, session {session_id}: {e}"
            )
            return None


class QdrantManager:
    """Manages interaction with Qdrant Vector Store using Nomic/Ollama embeddings."""

    def __init__(
        self,
        url: str = None,
        api_key: str = None,
    ):
        self.url = url or os.getenv("QDRANT_URL")
        self.api_key = api_key or os.getenv("QDRANT_API_KEY")
        try:
            self.client = QdrantClient(url=self.url, api_key=self.api_key)
            self._ensure_collections_exist()
        except Exception as e:
            logger.error(f"Failed to initialize Qdrant client at {self.url}: {e}")
            self.client = None

    def _ensure_collections_exist(self):
        if not self.client:
            return
        collections_to_ensure = {
            QDRANT_COLLECTION_VULNS: "Known vulnerability signatures and details",
            QDRANT_COLLECTION_PAYLOADS: "Common payloads and exploits",
            QDRANT_COLLECTION_REPORTS: "Historical pentest data/report summaries",
        }
        try:
            existing_collections = [
                col.name for col in self.client.get_collections().collections
            ]
            for col_name, desc in collections_to_ensure.items():
                if col_name not in existing_collections:
                    # Check if collection exists (again, to be safe with potential lib changes)
                    # Some Qdrant versions might not have collection_exists or behave differently
                    try:
                        self.client.get_collection(collection_name=col_name)
                    except Exception:  # Assuming exception means it doesn't exist
                        logger.info(f"Creating Qdrant collection: {col_name}")
                        self.client.create_collection(
                            collection_name=col_name,
                            vectors_config=qdrant_models.VectorParams(
                                size=768,
                                distance=qdrant_models.Distance.COSINE,  # Ensure this size matches your embedding model
                            ),
                        )
        except Exception as e:
            logger.error(f"Error ensuring Qdrant collections exist: {e}")

    def add_entry(
        self,
        collection_name: str,
        text_content: str,
        metadata: Optional[Dict] = None,
        entry_id: Optional[str] = None,
    ):
        if not self.client:
            logger.warning(
                f"Qdrant client not available. Cannot add entry to {collection_name}."
            )
            return
        if metadata is None:
            metadata = {}
        metadata["text_content"] = text_content  # Storing full text in payload is good

        try:
            embedding = get_embedding(text_content)
            if embedding is None:
                logger.error(f"Failed to get embedding for text: {text_content[:100]}")
                return

            final_id = entry_id or str(uuid.uuid4())
            self.client.upsert(
                collection_name=collection_name,
                points=[
                    qdrant_models.PointStruct(
                        id=final_id, vector=embedding, payload=metadata
                    )
                ],
            )
            logger.info(
                f"[Qdrant] Added entry to {collection_name} (ID: {final_id}): {text_content[:50]}..."
            )
        except Exception as e:
            logger.error(
                f"Error adding entry to Qdrant collection {collection_name}: {e}"
            )

    def search_entries(
        self, collection_name: str, query_text: str, limit: int = 5
    ) -> List[Dict]:
        if not self.client:
            logger.warning(
                f"Qdrant client not available. Cannot search {collection_name}."
            )
            return []

        try:
            query_embedding = get_embedding(query_text)
            if query_embedding is None:
                logger.error(f"Failed to get embedding for query: {query_text[:100]}")
                return []

            search_result = self.client.search(
                collection_name=collection_name,
                query_vector=query_embedding,
                limit=limit,
                with_payload=True,
            )
            results = [
                {"id": hit.id, "score": hit.score, "payload": hit.payload}
                for hit in search_result
            ]
            logger.info(
                f"[Qdrant] Searched {collection_name} for '{query_text}', found {len(results)} results."
            )
            return results
        except Exception as e:
            logger.error(f"Error searching Qdrant collection {collection_name}: {e}")
            return []


mem0_storage = PentestMemoryClient(collection_name="web_pentest_memories")
qdrant_db = QdrantManager()


# --- Agent State Definition ---
class TargetInfo(BaseModel):
    domain: Optional[str] = None
    ip_addresses: List[str] = Field(default_factory=list)
    subdomains: List[str] = Field(default_factory=list)
    technologies: List[str] = Field(
        default_factory=list
    )  # Populated by Nmap/other tools


class VulnerabilityInfo(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    name: str
    description: str
    severity: Optional[
        Literal["Critical", "High", "Medium", "Low", "Informational"]
    ] = None
    target_component: Optional[str] = None  # e.g., specific URL, parameter
    scanner_tool: Optional[str] = None
    raw_output: Optional[str] = None  # Store raw tool output if relevant


class AccessPointInfo(
    BaseModel
):  # Less critical for simplified version, but kept for schema
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    method: str
    target: str
    credentials_obtained: Optional[str] = None
    shell_url: Optional[str] = None


class PersistenceMechanismInfo(BaseModel):  # Less critical for simplified version
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    type: str
    details: str
    location: str


class WebPentestState(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]
    user_id: str
    session_id: str

    target_info: TargetInfo
    recon_findings: Dict[str, Any]  # Stores tool outputs and flags like 'whois_done'
    identified_vulnerabilities: List[VulnerabilityInfo]  # For Nmap, ZAP findings
    gained_access_points: List[AccessPointInfo]
    persistence_mechanisms: List[PersistenceMechanismInfo]

    current_phase: Literal[
        "initialization",  # Agent needs to get target
        "automated_recon",  # Agent runs whois, nslookup, nmap
        "interactive_guidance",  # Agent is conversational, awaiting user prompts
        "completed",
    ]
    # phase_objective: Optional[str] # Less critical with simplified phases

    pending_tool_guidance: Optional[str]
    requires_user_input_for_tool: Optional[str]
    last_tool_raw_output: Optional[str]

    report_data_summary: Optional[
        str
    ]  # Can be summary of automated recon or full report
    timeline: List[Dict]
    tool_failures: Dict[
        str, int
    ]  # Tracks failures for a given tool in the current session
    # --- NEW FIELDS FOR INTENT/Q&A ---
    intent: Optional[Literal["pentest", "general_qa"]]
    general_qa_answer: Optional[str]


# --- Pentesting Tools (as Pydantic models for LangChain tool usage by LLM) ---


def run_cli_command(command: str, timeout: int = 60) -> str:
    try:
        logger.info(f"Executing CLI: {command}")
        process = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=timeout,
            check=False,  # Important: check=False to handle non-zero exit codes gracefully
        )
        if process.returncode == 0:
            return process.stdout.strip()
        else:
            # Combine stdout and stderr for more context on errors
            output = process.stdout.strip() + "\n" + process.stderr.strip()
            return f"Error (code {process.returncode}): {output.strip()}"
    except subprocess.TimeoutExpired:
        logger.error(f"Command timed out: {command}")
        return "Error: Command timed out."
    except Exception as e:
        logger.error(f"Error executing command '{command}': {e}")
        return f"Error: {e}"


class WhoisInput(BaseModel):
    domain: str = Field(
        description="The domain name to perform a WHOIS lookup on (e.g., example.com)."
    )


@tool(
    "whois_lookup_tool",
    args_schema=WhoisInput,
    description="Performs a WHOIS lookup on a domain to find registration information.",
)
def whois_lookup_tool(domain: str) -> str:
    """Performs a WHOIS lookup on a domain to find registration information."""
    return run_cli_command(f"whois {domain}")


class NslookupInput(BaseModel):
    domain: str = Field(
        description="The domain name for DNS enumeration (e.g., example.com)."
    )


@tool(
    "nslookup_tool",
    args_schema=NslookupInput,
    description="Performs DNS enumeration to find IP addresses for a domain.",
)
def nslookup_tool(domain: str) -> str:
    """Performs DNS enumeration (e.g., finding IP addresses) for a domain."""
    return run_cli_command(f"nslookup {domain}")


class NmapScanInput(BaseModel):
    target: str = Field(description="The IP address or hostname to scan with Nmap.")
    flags: Optional[str] = Field(
        description="Optional Nmap flags (e.g., -sV -T4 -p-). Default is a common safe scan.",
        default="-sV -T4 -A -Pn",  # Added -A for OS/Version detection, -Pn to skip host discovery (treat as up)
    )


@tool(
    "nmap_scan_tool",
    args_schema=NmapScanInput,
    description="Discovers open ports, services, OS, and versions on a target using Nmap.",
)
def nmap_scan_tool(target: str, flags: Optional[str] = "-sV -T4 -A -Pn") -> str:
    """Discovers open ports, services, OS, and versions on a target using Nmap."""
    return run_cli_command(f"nmap {flags} {target}")


class SearchQdrantPayloadsInput(BaseModel):
    query: str = Field(
        description="Description of the vulnerability or desired payload type to search for."
    )


@tool(
    "search_qdrant_payloads",
    args_schema=SearchQdrantPayloadsInput,
    description="Searches the Qdrant vector store for relevant payloads or exploits.",
)
def search_qdrant_payloads_tool(query: str) -> List[Dict]:
    """Searches the Qdrant vector store for relevant payloads or exploits based on a query."""
    if not qdrant_db or not qdrant_db.client:
        return [{"error": "Qdrant client not available."}]
    return qdrant_db.search_entries(QDRANT_COLLECTION_PAYLOADS, query, limit=3)


class GuideToolInput(BaseModel):
    target_url_or_info: str = Field(
        description="The target URL or relevant information for the tool."
    )
    additional_instructions: Optional[str] = Field(
        description="Any specific focus for the manual tool usage."
    )


@tool(
    "guide_owasp_zap_scan",
    args_schema=GuideToolInput,
    description="Provides user guidance for performing an OWASP ZAP scan.",
)
def guide_owasp_zap_scan_tool(
    target_url_or_info: str, additional_instructions: Optional[str] = None
) -> str:
    guidance = (
        f"USER ACTION REQUIRED: Please perform an OWASP ZAP scan on '{target_url_or_info}'.\n"
        f"1. Open OWASP ZAP.\n"
        f"2. Use 'Quick Start' with URL: {target_url_or_info}, then click 'Attack'.\n"
        f"3. For more control, manually explore the site with ZAP as a proxy, then run Active Scan.\n"
    )
    if additional_instructions:
        guidance += f"4. Specific focus: {additional_instructions}\n"
    guidance += "5. After completion, review the 'Alerts' tab. Summarize key vulnerabilities found (name, severity, affected URL/parameter) and provide them back to me."
    return f"USER_GUIDANCE_PROVIDED_FOR::OWASP_ZAP::{guidance}"


@tool(
    "guide_metasploit_exploitation",
    args_schema=GuideToolInput,
    description="Provides user guidance for exploitation using Metasploit.",
)
def guide_metasploit_exploitation_tool(
    target_url_or_info: str, additional_instructions: Optional[str] = None
) -> str:
    guidance = (
        f"USER ACTION REQUIRED: Attempt exploitation using Metasploit based on information: '{target_url_or_info}'.\n"
        f"1. Launch `msfconsole`.\n"
        f"2. Search for relevant exploits (e.g., `search type:exploit platform:linux Apache Struts`).\n"
        f"3. Select an exploit: `use exploit/path/to/module`.\n"
        f"4. Set options: `set RHOSTS <target_ip>`, `set LHOST <your_ip>`, payload etc.\n"
    )
    if additional_instructions:
        guidance += f"5. Specific guidance: {additional_instructions}\n"
    guidance += "6. Run `exploit` or `run`.\n7. Report back the outcome: success (e.g., shell obtained, data exfiltrated) or failure, and any relevant details (exploit used, session ID)."
    return f"USER_GUIDANCE_PROVIDED_FOR::METASPLOIT::{guidance}"


pentest_tools = [
    whois_lookup_tool,
    nslookup_tool,
    nmap_scan_tool,
    guide_owasp_zap_scan_tool,
    guide_metasploit_exploitation_tool,
    search_qdrant_payloads_tool,
]
tool_map = {t.name: t for t in pentest_tools}


# --- Main Agent Class ---
class WebPentestAgent:
    def __init__(
        self,
        user_id: str,
        session_id: str,
        target_domain: Optional[str] = None,
        use_openai: bool = False,
    ):
        self.user_id = user_id
        self.session_id = session_id
        self.llm = self.setup_model(use_openai)

        self.graph = self._build_graph()
        self.agent_runnable = self.graph.compile(checkpointer=None)

        logger.info(
            f"WebPentestAgent initialized for user '{user_id}', session '{session_id}'."
        )
        self.initial_state = WebPentestState(
            messages=[],
            user_id=user_id,
            session_id=session_id,
            target_info=(
                TargetInfo(domain=target_domain) if target_domain else TargetInfo()
            ),
            recon_findings={"recon_done_flags": {}},  # Initialize recon_done_flags
            identified_vulnerabilities=[],
            gained_access_points=[],
            persistence_mechanisms=[],
            current_phase="initialization",
            pending_tool_guidance=None,
            requires_user_input_for_tool=None,
            last_tool_raw_output=None,
            report_data_summary=None,
            timeline=[],
            tool_failures={},
            intent=None,
            general_qa_answer=None,
        )

    def setup_model(self, use_openai: bool = False):
        if use_openai and os.environ.get("OPENAI_API_KEY"):
            model_name = os.getenv("OPENAI_MODEL_NAME", "gpt-4o")
            logger.info(f"Using OpenAI model: {model_name}")
            return ChatOpenAI(
                api_key=os.environ.get("OPENAI_API_KEY"),
                model=model_name,
                temperature=0.1,
                streaming=True,
            )
        else:
            model_name = os.getenv("OLLAMA_MODEL_NAME", "qwen2.5:7b")
            logger.info(f"Using Ollama model: {model_name} from http://localhost:11434")
            return ChatOllama(
                model=model_name,
                temperature=0.1,
                base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
            )

    def _get_phase_prompt_and_tools(
        self, state: WebPentestState
    ) -> tuple[str, List[BaseModel]]:  # Tools list still returned for binding
        phase = state["current_phase"]
        target_domain_str = state["target_info"].domain or "Not set"
        target_ips_str = (
            ", ".join(state["target_info"].ip_addresses)
            if state["target_info"].ip_addresses
            else "Not set"
        )
        target_summary = f"Target: Domain={target_domain_str}, IPs=[{target_ips_str}]"

        objective = ""

        if phase == "initialization":
            objective = (
                "Your primary goal is to obtain the target domain or IP address from the user. "
                "If a target has already been provided in the conversation history, confirm it. "
                "Once a target is clearly identified, respond with ONLY 'TARGET_ACQUIRED: [domain/IP]' to proceed. "
                "If no target is clear, ask the user for it. Example: 'Please provide the target domain or IP address.'"
            )
        elif phase == "automated_recon":
            objective = (
                "You are in the automated reconnaissance phase. "
                "A specific tool execution has been requested by the system (check for 'ACTION_REQUIRED:' in recent messages). "
                "Execute ONLY the specified tool (whois, nslookup, or nmap) on the identified target. "
                "If no specific tool is currently requested by an 'ACTION_REQUIRED:' message, state that you are awaiting system direction for the next automated reconnaissance step."
            )
        elif phase == "interactive_guidance":
            objective = (
                "Automated reconnaissance is complete. A summary of findings should have been presented. "
                "You are now in interactive guidance mode. Respond to user queries, provide advice on next steps, "
                "and use any available tools (including scanning, payload search, or guided exploitation tools like ZAP/Metasploit) "
                "if the user requests or if it's a logical next step based on the conversation. "
                "You can ask clarifying questions to better understand the user's needs."
            )
            target_summary += f"\n Recon Findings: {str(state['recon_findings'])[:300]}"
            vuln_summary = [
                v.model_dump(exclude_none=True)
                for v in state["identified_vulnerabilities"]
            ]
            target_summary += (
                f"\n Vulnerabilities (from Nmap/etc.): {str(vuln_summary)[:300]}"
            )
        else:  # completed
            objective = "The penetration test session is completed. You can provide a final summary if appropriate or await session termination."

        system_prompt = f"""You are a Web Penetration Testing Assistant.
Current Phase: {phase.upper()}
Objective: {objective}
{target_summary}

Tool Usage:
- If you need to use a tool, respond with a JSON list of tool calls. Example: `[{{\"tool_name\": \"tool_name\", \"tool_input\": {{\"arg1\": \"value1\"}}}}]`
- For 'guidance' tools (like ZAP, Metasploit), your call will trigger user instructions. The system will inform you when user guidance has been prepared.
- When using tools, ensure you ONLY output the JSON for the tool call, no other text.

User Interaction & Directives:
- If you need to ask the user a question or provide information, respond with text directly.
- If the user says 'exit' or similar, respond with ONLY "SESSION_END" to terminate.
- In 'initialization' phase, if you identify/confirm a target, respond with ONLY "TARGET_ACQUIRED: [domain/IP]".

Current findings snapshot (abbreviated):
Recon: {str(state['recon_findings'])[:300]}
Vulnerabilities: {str([v.name for v in state['identified_vulnerabilities']])[:300]}

What is your next action or question based on the current phase, objective, and conversation history?
"""
        return (
            system_prompt,
            pentest_tools,
        )  # All tools are always available for binding

    # --- Graph Nodes ---
    def initial_setup_node(self, state: WebPentestState) -> WebPentestState:
        logger.info("--- Node: Initial Setup ---")

        if "recon_done_flags" not in state["recon_findings"]:  # Ensure initialization
            state["recon_findings"]["recon_done_flags"] = {}
        if (
            "tool_failures" not in state or state["tool_failures"] is None
        ):  # Ensure initialization
            state["tool_failures"] = {}

        # Try to extract target from the last HumanMessage if not already set
        if not state["target_info"].domain and not state["target_info"].ip_addresses:
            if state["messages"] and isinstance(state["messages"][-1], HumanMessage):
                msg_content = state["messages"][-1].content
                # Regex for domain or IP
                potential_targets = re.findall(
                    r"(?:(?:[a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,6})|(?:\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})",
                    msg_content,
                )
                if potential_targets:
                    target = potential_targets[0]  # Take the first one found
                    if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", target):
                        if target not in state["target_info"].ip_addresses:
                            state["target_info"].ip_addresses.append(target)
                        logger.info(
                            f"Target IP extracted from initial user input: {target}"
                        )
                    else:
                        state["target_info"].domain = target
                        logger.info(
                            f"Target domain extracted from initial user input: {target}"
                        )

        if state["target_info"].domain or state["target_info"].ip_addresses:
            target_name = (
                state["target_info"].domain or state["target_info"].ip_addresses[0]
            )
            state["current_phase"] = "automated_recon"
            # System message can be helpful for clarity in logs/LLM context
            state["messages"] = add_messages(
                state["messages"],
                [
                    SystemMessage(
                        content=f"Target identified: {target_name}. Proceeding to automated reconnaissance."
                    )
                ],
            )
            logger.info(f"Target {target_name} present. Moving to automated_recon.")
        else:
            state["current_phase"] = "initialization"
            logger.info(
                "No target identified. Staying in initialization phase for LLM to ask."
            )
            # Optionally, add a system message if first time in init.
            if not any(
                isinstance(m, SystemMessage)
                and "ask for the primary target" in m.content
                for m in state["messages"]
            ):
                state["messages"] = add_messages(
                    state["messages"],
                    [
                        SystemMessage(
                            content="No target specified. The agent will ask for the primary target domain or IP address."
                        )
                    ],
                )
        return state

    def automated_recon_controller_node(
        self, state: WebPentestState
    ) -> WebPentestState:
        logger.info("--- Node: Automated Recon Controller ---")
        target_domain = state["target_info"].domain
        target_ip = (
            state["target_info"].ip_addresses[0]
            if state["target_info"].ip_addresses
            else None
        )
        effective_target = target_domain or target_ip  # Nmap can use domain or IP

        if not effective_target:
            logger.warning(
                "Automated Recon Controller: No target. Transitioning to initialization."
            )
            state["current_phase"] = "initialization"
            state["messages"] = add_messages(
                state["messages"],
                [
                    SystemMessage(
                        content="Error: Target information is missing. Please provide the target."
                    )
                ],
            )
            return state

        recon_done_flags = state["recon_findings"].get("recon_done_flags", {})
        pending_actions = []

        if not recon_done_flags.get("whois_done") and target_domain:
            pending_actions.append(
                SystemMessage(
                    content=f"ACTION_REQUIRED: Use 'whois_lookup_tool' on domain {target_domain}."
                )
            )
        elif not recon_done_flags.get("nslookup_done") and target_domain:
            pending_actions.append(
                SystemMessage(
                    content=f"ACTION_REQUIRED: Use 'nslookup_tool' on domain {target_domain}."
                )
            )
        elif not recon_done_flags.get("nmap_done") and effective_target:
            pending_actions.append(
                SystemMessage(
                    content=f"ACTION_REQUIRED: Use 'nmap_scan_tool' on target {effective_target} with default flags."
                )
            )
        else:
            logger.info(
                "All automated reconnaissance steps completed or not applicable."
            )
            state["current_phase"] = "interactive_guidance"

            summary_parts = ["Automated reconnaissance complete. Summary:"]
            if state["recon_findings"].get("whois"):
                summary_parts.append(
                    f"- WHOIS Output: Processed (details in logs/timeline)."
                )
            if state["recon_findings"].get("nslookup"):
                summary_parts.append(
                    f"- NSLOOKUP Output: Processed (details in logs/timeline)."
                )
            if state["recon_findings"].get("nmap_scan"):
                summary_parts.append(
                    f"- NMAP Scan Output: Processed. Open ports: {state['recon_findings'].get('open_ports', 'None detected')}."
                )

            summary_message = (
                "\n".join(summary_parts)
                + "\n\nWhat would you like to investigate next?"
            )
            state["messages"] = add_messages(
                state["messages"], [SystemMessage(content=summary_message)]
            )
            # This message primes the LLM for its response in agent_think_and_act
            return state

        if pending_actions:
            state["messages"] = add_messages(state["messages"], pending_actions)

        return state

    def agent_think_and_act_node(self, state: WebPentestState) -> WebPentestState:
        logger.info(
            f"--- Node: Agent Think and Act (Phase: {state['current_phase']}) ---"
        )

        if state.get("requires_user_input_for_tool"):
            logger.warning(
                "Agent in 'requires_user_input' state but 'think_and_act' was called. This should be handled by graph logic."
            )
            return state  # Graph's conditional edge should route to user input handling

        system_prompt_content, tools_for_binding = self._get_phase_prompt_and_tools(
            state
        )
        llm_with_tools = self.llm.bind_tools(tools_for_binding)

        # Construct messages for LLM: System prompt + recent conversation history
        # Limit history to avoid excessive token usage, adjust as needed
        MAX_HISTORY_MESSAGES = 10
        history_messages = state["messages"][-MAX_HISTORY_MESSAGES:]

        # Ensure the first message is the system prompt for this turn
        current_llm_messages = [
            SystemMessage(content=system_prompt_content)
        ] + history_messages

        ai_response_obj = llm_with_tools.invoke(current_llm_messages)
        state["messages"] = add_messages(state["messages"], [ai_response_obj])
        return state

    def process_agent_response_node(self, state: WebPentestState) -> WebPentestState:
        logger.info("--- Node: Process Agent Response ---")
        last_message = state["messages"][-1]
        state["pending_tool_guidance"] = None

        if not isinstance(last_message, AIMessage):
            logger.warning("Last message is not AIMessage, skipping processing.")
            return state

        ai_message_content_str = ""
        if isinstance(last_message.content, str):
            ai_message_content_str = last_message.content.strip()

        if ai_message_content_str.startswith("TARGET_ACQUIRED:"):
            target_str = ai_message_content_str.split(":", 1)[1].strip()
            # Update target_info more robustly
            if not state["target_info"].domain and not re.match(
                r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", target_str
            ):
                state["target_info"].domain = target_str
            elif not state["target_info"].ip_addresses and re.match(
                r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", target_str
            ):
                if target_str not in state["target_info"].ip_addresses:
                    state["target_info"].ip_addresses.append(target_str)

            logger.info(
                f"LLM confirmed/acquired target: {target_str}. Transitioning to automated_recon."
            )
            state["current_phase"] = "automated_recon"
            # Add a system message for clarity for the LLM if it re-reads history.
            state["messages"] = add_messages(
                state["messages"],
                [
                    SystemMessage(
                        content=f"System: Target acquisition confirmed for {target_str}. Phase changed to automated_recon."
                    )
                ],
            )
            return state

        elif ai_message_content_str == "SESSION_END":
            logger.info("LLM indicated session end.")
            state["current_phase"] = "completed"
            state["messages"] = add_messages(
                state["messages"], [SystemMessage(content="Session ended by agent.")]
            )
            return state

        if getattr(last_message, "tool_calls", None):
            logger.info(f"LLM initiated tool calls: {last_message.tool_calls}")
        elif ai_message_content_str:
            logger.info(f"LLM text response: {ai_message_content_str[:100]}...")
            state["requires_user_input_for_tool"] = None
        return state

    def _increment_tool_failure(self, state, tool_name):
        state["tool_failures"][tool_name] = state["tool_failures"].get(tool_name, 0) + 1
        return state["tool_failures"][tool_name]

    def _reset_tool_failure(self, state, tool_name):
        if tool_name in state["tool_failures"]:
            state["tool_failures"][tool_name] = 0

    def execute_tool_node(self, state: WebPentestState) -> WebPentestState:
        logger.info("--- Node: Execute Tool ---")
        last_message = state["messages"][-1]

        if not isinstance(last_message, AIMessage) or not getattr(
            last_message, "tool_calls", None
        ):
            logger.info("No tool calls in last AI message or last message not AI.")
            return state

        MAX_TOOL_FAILURES = 3  # Max failures before skipping a recon tool

        for tool_call_obj in last_message.tool_calls:
            if isinstance(tool_call_obj, dict):
                tool_name = tool_call_obj["name"]
                tool_args = tool_call_obj["args"]
                tool_id = tool_call_obj.get("id")
            else:
                tool_name = tool_call_obj.name
                tool_args = tool_call_obj.args
                tool_id = tool_call_obj.id
            selected_tool = tool_map.get(tool_name)

            result_content = ""
            fail_count = 0

            if not selected_tool:
                result_content = f"Error: Tool '{tool_name}' not found."
                logger.error(result_content)
            else:
                logger.info(f"Executing tool: {tool_name} with args: {tool_args}")
                try:
                    observation = selected_tool.invoke(tool_args)
                    result_content = str(observation)
                    self._reset_tool_failure(state, tool_name)

                    if result_content.startswith("USER_GUIDANCE_PROVIDED_FOR::"):
                        _, tool_key, guidance_text = result_content.split("::", 2)
                        state["pending_tool_guidance"] = guidance_text
                        state["requires_user_input_for_tool"] = tool_key
                        logger.info(
                            f"Tool {tool_key} requires user input. Guidance prepared."
                        )
                        result_content = f"User guidance for {tool_key} has been prepared. Awaiting user input."
                except Exception as e:
                    result_content = f"Error executing tool {tool_name}: {e}"
                    logger.error(result_content, exc_info=True)
                    fail_count = self._increment_tool_failure(state, tool_name)

                    if (
                        state["current_phase"] == "automated_recon"
                        and fail_count >= MAX_TOOL_FAILURES
                    ):
                        skip_msg = f"Tool '{tool_name}' failed {fail_count} times during automated_recon. Marking as complete and moving on."
                        logger.warning(skip_msg)

                        if "recon_done_flags" not in state["recon_findings"]:
                            state["recon_findings"]["recon_done_flags"] = {}
                        tool_type_for_flag = tool_name.split("_")[0]
                        state["recon_findings"]["recon_done_flags"][
                            f"{tool_type_for_flag}_done"
                        ] = True
                        result_content = skip_msg
                        self._reset_tool_failure(state, tool_name)
                        # The graph will route back to automated_recon_controller, which will pick the next tool.
                        # No need to change current_phase here.

            # Strictly ensure ToolMessage is only added if the last message is an AIMessage with tool_calls
            if (
                tool_id is not None
                and isinstance(state["messages"][-1], AIMessage)
                and getattr(state["messages"][-1], "tool_calls", None)
            ):
                state["messages"] = add_messages(
                    state["messages"],
                    [ToolMessage(content=result_content, tool_call_id=tool_id)],
                )
            state["last_tool_raw_output"] = result_content

            # Perform post-processing for this specific tool call result
            self._post_tool_processing(state, tool_name, tool_args, result_content)

            if (
                state["current_phase"] == "automated_recon"
                and fail_count >= MAX_TOOL_FAILURES
            ):
                break  # Stop processing further tool calls in this batch if one critical recon tool failed hard.

        return state

    def _post_tool_processing(
        self,
        state: WebPentestState,
        tool_name: str,
        tool_args: Dict,
        result_content: str,
    ):
        logger.info(f"Post-processing for tool {tool_name} output.")
        now = datetime.datetime.now(datetime.timezone.utc).isoformat()
        event = {
            "timestamp": now,
            "phase": state["current_phase"],
            "tool": tool_name,
            "args": tool_args,
            "result_summary": (
                result_content[:200] + "..."
                if len(result_content) > 200
                else result_content
            ),  # Store only summary in timeline
            "user_id": state["user_id"],
            "session_id": state["session_id"],
        }

        if "recon_done_flags" not in state["recon_findings"]:  # Ensure exists
            state["recon_findings"]["recon_done_flags"] = {}

        if tool_name == "whois_lookup_tool":
            state["recon_findings"]["whois"] = result_content
            state["recon_findings"]["recon_done_flags"]["whois_done"] = True
        elif tool_name == "nslookup_tool":
            state["recon_findings"]["nslookup"] = result_content
            state["recon_findings"]["recon_done_flags"]["nslookup_done"] = True
            # Try to extract IPs from nslookup to add to target_info
            # This is a basic example; nslookup output can be complex
            ips_found = re.findall(
                r"Address:\s*(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})", result_content
            )
            for ip in ips_found:
                if ip not in state["target_info"].ip_addresses:
                    state["target_info"].ip_addresses.append(ip)
                    logger.info(f"Added IP from nslookup: {ip}")
        elif tool_name == "nmap_scan_tool":
            state["recon_findings"]["nmap_scan"] = result_content
            state["recon_findings"]["recon_done_flags"]["nmap_done"] = True
            open_ports = sorted(
                list(set(re.findall(r"(\d+)/tcp\s+open", result_content)))
            )  # Unique sorted ports
            state["recon_findings"]["open_ports"] = open_ports

            # Create a simple vulnerability entry for Nmap findings
            vuln_desc = f"Nmap scan on {tool_args.get('target')} found open TCP ports: {', '.join(open_ports) if open_ports else 'None detailed'}."
            if (
                "os" in result_content.lower() or "service" in result_content.lower()
            ):  # Basic check if -A yielded info
                vuln_desc += " OS/Service detection was attempted."

            vuln = VulnerabilityInfo(
                name=f"Nmap Scan Summary for {tool_args.get('target')}",
                description=vuln_desc,
                scanner_tool="Nmap",
                raw_output=result_content,  # Keep full output if needed elsewhere
                severity="Informational",  # Nmap itself is informational unless specific vulns found by scripts
            )
            state["identified_vulnerabilities"].append(vuln)
            event["vulnerability_name"] = vuln.name  # Add to timeline event

        if "timeline" not in state or state["timeline"] is None:
            state["timeline"] = []
        state["timeline"].append(event)

        # Save event to Qdrant
        if qdrant_db and qdrant_db.client:
            qdrant_db.add_entry(
                QDRANT_COLLECTION_REPORTS,
                json.dumps(event),  # Store the structured event
                metadata={
                    "phase": state["current_phase"],
                    "tool": tool_name,
                    "user_id": state["user_id"],
                    "session_id": state["session_id"],
                    "type": "timeline_event",
                    "timestamp": now,
                    "target": state["target_info"].domain
                    or (
                        state["target_info"].ip_addresses[0]
                        if state["target_info"].ip_addresses
                        else "unknown"
                    ),
                },
            )
        # Save conversational memory to Mem0
        if mem0_storage and mem0_storage.client:
            # Save the current message turn (human + AI + tool) to Mem0
            # This example saves the tool result event as a proxy for the turn.
            # A more robust approach would save actual HumanMessage/AIMessage content.
            mem0_messages = [
                {
                    "role": "system",
                    "content": f"Tool {tool_name} executed. Result: {event['result_summary']}",
                }
            ]
            mem0_storage.add(
                messages=mem0_messages,
                user_id=state["user_id"],
                session_id=state["session_id"],
                metadata={"phase": state["current_phase"], "tool_event": tool_name},
            )

    def request_user_input_node(self, state: WebPentestState) -> WebPentestState:
        logger.info("--- Node: Request User Input ---")
        guidance = state.get("pending_tool_guidance")
        tool_name_waiting = state.get("requires_user_input_for_tool")

        if guidance and tool_name_waiting:
            user_prompt_message = f"{guidance}\n\nPlease provide the results/summary for {tool_name_waiting}:"
            state["messages"] = add_messages(
                state["messages"], [AIMessage(content=user_prompt_message)]
            )
            logger.info(f"Agent is now awaiting user input for {tool_name_waiting}.")
        else:
            logger.error("Request User Input node reached without pending guidance.")
        state["pending_tool_guidance"] = None
        return state

    def process_user_tool_input_node(self, state: WebPentestState) -> WebPentestState:
        logger.info("--- Node: Process User Tool Input ---")
        last_message = state["messages"][-1]
        tool_name_answered = state["requires_user_input_for_tool"]

        if isinstance(last_message, HumanMessage) and tool_name_answered:
            user_provided_data = last_message.content
            logger.info(
                f"Received user input for tool {tool_name_answered}: {user_provided_data[:100]}..."
            )

            system_inform_message = (
                f"User provided results for {tool_name_answered}: {user_provided_data}"
            )
            state["messages"] = add_messages(
                state["messages"], [SystemMessage(content=system_inform_message)]
            )

            # Example: Basic processing for ZAP results
            if tool_name_answered == "OWASP_ZAP":
                vuln = VulnerabilityInfo(
                    name=f"ZAP Scan finding (user-reported for {state['target_info'].domain or 'target'})",
                    description=user_provided_data,  # User's summary
                    scanner_tool="OWASP ZAP (manual)",
                    severity="Medium",  # Default, user might specify
                )
                state["identified_vulnerabilities"].append(vuln)
                if mem0_storage and mem0_storage.client:
                    mem0_storage.add(
                        messages=[
                            {"role": "user", "content": user_provided_data}
                        ],  # Storing user's report
                        user_id=state["user_id"],
                        session_id=state["session_id"],
                        metadata={
                            "phase": state["current_phase"],
                            "tool": "OWASP_ZAP_UserReport",
                        },
                    )
                if qdrant_db and qdrant_db.client:
                    qdrant_db.add_entry(
                        QDRANT_COLLECTION_VULNS,
                        f"ZAP (user summary for {state['target_info'].domain}): {user_provided_data[:500]}",
                        metadata={
                            "tool": "OWASP_ZAP",
                            "target": state["target_info"].domain or "unknown",
                        },
                    )

            state["requires_user_input_for_tool"] = None
            state["last_tool_raw_output"] = user_provided_data
        else:
            logger.warning(
                "Process User Tool Input node called without valid preceding user message or tool context."
            )
        return state

    def generate_report_node(self, state: WebPentestState) -> WebPentestState:
        # This node is less critical in the simplified flow but kept for potential use.
        logger.info("--- Node: Generate Report (if called) ---")
        timeline_summary = "\n".join(
            [
                f"- [{e.get('timestamp', '')[:19]}] Phase: {e.get('phase', '')}, Tool: {e.get('tool', '')}, Args: {e.get('args', {})}, Summary: {e.get('result_summary', '')}"
                for e in state.get("timeline", [])
            ]
        )

        summary = "Penetration Test Summary Report:\n"
        summary += f"Target: {state['target_info'].model_dump_json(indent=1)}\n"
        summary += f"Recon Findings Highlights:\n"
        summary += f"  WHOIS data captured: {'yes' if state['recon_findings'].get('whois') else 'no'}\n"
        summary += f"  NSLOOKUP data captured: {'yes' if state['recon_findings'].get('nslookup') else 'no'}\n"
        summary += f"  NMAP scan performed: {'yes' if state['recon_findings'].get('nmap_scan') else 'no'}\n"
        summary += f"  Open Ports (from Nmap): {', '.join(state['recon_findings'].get('open_ports', [])) or 'None detected'}\n"

        if state["identified_vulnerabilities"]:
            summary += f"Identified Vulnerabilities/Observations ({len(state['identified_vulnerabilities'])}):\n"
            for v in state["identified_vulnerabilities"]:
                summary += f"  - Name: {v.name}, Tool: {v.scanner_tool or 'N/A'}, Severity: {v.severity or 'N/A'}\n"
                summary += (
                    f"    Description: {v.description[:150]}...\n"  # Brief description
                )
        else:
            summary += "No specific vulnerabilities logged apart from informational findings.\n"

        # Access/Persistence are unlikely in simplified flow but included if populated
        if state["gained_access_points"]:
            summary += f"Gained Access Points: {len(state['gained_access_points'])}\n"  # List details if needed
        if state["persistence_mechanisms"]:
            summary += (
                f"Persistence Mechanisms: {len(state['persistence_mechanisms'])}\n"
            )

        summary += f"\n--- Detailed Timeline of Actions ---\n{timeline_summary}\n"

        state["report_data_summary"] = summary
        state["messages"] = add_messages(
            state["messages"], [AIMessage(content=summary)]
        )  # Agent "says" the report
        logger.info("Summary report generated.")

        if mem0_storage and mem0_storage.client:
            mem0_storage.add(
                messages=[{"role": "assistant", "content": summary}],
                user_id=state["user_id"],
                session_id=state["session_id"],
                metadata={"type": "final_report_summary"},
            )
        if qdrant_db and qdrant_db.client:
            qdrant_db.add_entry(
                QDRANT_COLLECTION_REPORTS,
                summary,
                metadata={
                    "target": state["target_info"].domain or "unknown",
                    "type": "FinalReport",
                },
            )
        state["current_phase"] = "completed"  # Mark as completed after report
        return state

    def classify_intent_node(self, state: WebPentestState) -> WebPentestState:
        """Classify the user query as pentest or general_qa."""
        logger.info("--- Node: Classify Intent ---")
        # Use the last human message as the query
        user_query = None
        for msg in reversed(state["messages"]):
            if isinstance(msg, HumanMessage):
                user_query = msg.content
                break
        if not user_query:
            logger.warning(
                "No user query found for intent classification. Defaulting to pentest."
            )
            state["intent"] = "pentest"
            return state
        prompt = (
            "Classify the user's query as one of the following intents:\n"
            "1. pentest: The user wants to perform a penetration test, scan, vulnerability assessment, or hacking activity AND has provided a specific target domain (e.g. example.com) or IP address (e.g. 192.168.1.1).\n"
            "2. general_qa: The user is asking a general cybersecurity question, definition, advice, explanation, or making a pentest request without specifying a target domain/IP.\n"
            f"\nUser Query: {user_query}\n\nOutput ONLY the label: pentest or general_qa."
        )
        try:
            response = self.llm.invoke([SystemMessage(content=prompt)])
            label = response.content.strip().lower()
            if label not in ["pentest", "general_qa"]:
                logger.warning(
                    f"Unexpected intent label: {label}, defaulting to pentest."
                )
                label = "pentest"
            state["intent"] = label
        except Exception as e:
            logger.error(f"Intent classification failed: {e}. Defaulting to pentest.")
            state["intent"] = "pentest"
        return state

    def general_qa_response_node(self, state: WebPentestState) -> WebPentestState:
        """Answer general cybersecurity questions directly."""
        logger.info("--- Node: General QA Response ---")
        user_query = None
        for msg in reversed(state["messages"]):
            if isinstance(msg, HumanMessage):
                user_query = msg.content
                break
        if not user_query:
            logger.warning("No user query found for general QA.")
            state["general_qa_answer"] = "I couldn't find your question."
            return state
        prompt = (
            "You are a helpful cybersecurity assistant. Answer the user's question clearly and concisely.\n\n"
            f"User Question: {user_query}\n\nAnswer:"
        )
        try:
            response = self.llm.invoke([SystemMessage(content=prompt)])
            answer = response.content.strip()
            state["general_qa_answer"] = answer
            state["messages"] = add_messages(
                state["messages"], [AIMessage(content=answer)]
            )
        except Exception as e:
            logger.error(f"General QA response failed: {e}")
            state["general_qa_answer"] = (
                "I encountered an error trying to answer your question."
            )
            state["messages"] = add_messages(
                state["messages"], [AIMessage(content=state["general_qa_answer"])]
            )
        # Set phase to completed so the graph ends
        state["current_phase"] = "completed"
        return state

    # --- Graph Construction ---
    def _build_graph(self) -> StateGraph:
        graph = StateGraph(WebPentestState)
        # --- Add new nodes ---
        graph.add_node("classify_intent", self.classify_intent_node)
        graph.add_node("general_qa_response", self.general_qa_response_node)
        # --- Existing nodes ---
        graph.add_node("initial_setup", self.initial_setup_node)
        graph.add_node(
            "automated_recon_controller", self.automated_recon_controller_node
        )
        graph.add_node("agent_think_and_act", self.agent_think_and_act_node)
        graph.add_node("process_agent_response", self.process_agent_response_node)
        graph.add_node("execute_tool", self.execute_tool_node)
        graph.add_node("request_user_input", self.request_user_input_node)
        graph.add_node("process_user_tool_input", self.process_user_tool_input_node)
        graph.add_node("generate_report", self.generate_report_node)
        # --- Entry point: classify intent ---
        graph.set_entry_point("classify_intent")
        # --- Intent routing ---
        graph.add_conditional_edges(
            "classify_intent",
            lambda state: (
                "general_qa_response"
                if state.get("intent") == "general_qa"
                else "initial_setup"
            ),
            {
                "general_qa_response": "general_qa_response",
                "initial_setup": "initial_setup",
            },
        )
        # --- Existing workflow ---
        graph.add_conditional_edges(
            "initial_setup",
            lambda state: (
                "automated_recon_controller"
                if state["current_phase"] == "automated_recon"
                else "agent_think_and_act"
            ),
            {
                "automated_recon_controller": "automated_recon_controller",
                "agent_think_and_act": "agent_think_and_act",
            },
        )
        graph.add_edge("automated_recon_controller", "agent_think_and_act")
        graph.add_edge("agent_think_and_act", "process_agent_response")
        graph.add_conditional_edges(
            "process_agent_response",
            lambda state: (
                "execute_tool"
                if isinstance(state["messages"][-1], AIMessage)
                and getattr(state["messages"][-1], "tool_calls", None)
                else (
                    "completed"
                    if state["current_phase"] == "completed"
                    else (
                        "automated_recon_controller"
                        if state["current_phase"] == "automated_recon"
                        and not (
                            isinstance(state["messages"][-1], AIMessage)
                            and getattr(state["messages"][-1], "tool_calls", None)
                        )
                        else "agent_think_and_act"
                    )
                )
            ),
            {
                "execute_tool": "execute_tool",
                "automated_recon_controller": "automated_recon_controller",
                "agent_think_and_act": "agent_think_and_act",
                "completed": END,
            },
        )
        graph.add_conditional_edges(
            "execute_tool",
            lambda state: (
                "request_user_input"
                if state.get("requires_user_input_for_tool")
                else (
                    "automated_recon_controller"
                    if state["current_phase"] == "automated_recon"
                    else "agent_think_and_act"
                )
            ),
            {
                "request_user_input": "request_user_input",
                "automated_recon_controller": "automated_recon_controller",
                "agent_think_and_act": "agent_think_and_act",
            },
        )
        graph.add_edge("request_user_input", "process_user_tool_input")
        graph.add_edge("process_user_tool_input", "agent_think_and_act")
        graph.add_edge("generate_report", END)
        graph.add_edge("general_qa_response", END)
        return graph

    # Invoke method is not used by the __main__ loop but kept for other potential uses
    def invoke(
        self, human_query: Optional[str] = None, initial_target: Optional[str] = None
    ):
        current_state_dict = self.initial_state.copy()
        if initial_target and not current_state_dict["target_info"].domain:
            current_state_dict["target_info"].domain = initial_target
        if human_query:
            current_state_dict["messages"] = add_messages(
                current_state_dict["messages"], [HumanMessage(content=human_query)]
            )

        final_loop_state = None
        for s_update in self.agent_runnable.stream(
            current_state_dict, {"recursion_limit": 100}
        ):
            node_name = list(s_update.keys())[0]
            final_loop_state = s_update[node_name]
            logger.info(f"--- Stream Update from Node: {node_name} ---")
            if node_name == END or final_loop_state.get("current_phase") == "completed":
                break
            if final_loop_state.get("requires_user_input_for_tool"):
                logger.info(
                    f"Stream pause: awaiting user input for {final_loop_state['requires_user_input_for_tool']}"
                )
                # In a non-interactive invoke, this is where it might stop and return state.
                return final_loop_state
        return final_loop_state


# --- Example Usage ---
if __name__ == "__main__":
    USER_ID = "test_user_002"
    SESSION_ID = f"pentest_session_{uuid.uuid4()}"

    # Ensure API keys are handled (e.g. OPENAI_API_KEY for OpenAI models)
    # Ollama does not require an API key by default.
    # if not os.getenv("OPENAI_API_KEY"): # Only if using OpenAI
    #     print("Warning: OPENAI_API_KEY not set. Ollama will be used if available.")

    print("Initializing Web Pentest Agent...")
    # Determine if OpenAI should be used based on API key presence
    # Defaulting to Ollama (use_openai=False) as per prompt's lean towards local tools.
    # Set use_openai=True if you have OPENAI_API_KEY and prefer it.
    should_use_openai = bool(os.getenv("OPENAI_API_KEY"))
    agent = WebPentestAgent(
        user_id=USER_ID, session_id=SESSION_ID, use_openai=should_use_openai
    )

    current_pentest_state_dict = agent.initial_state.copy()

    print(f"Web Pentest Agent ready. Session ID: {SESSION_ID}")
    print(
        "Provide target (e.g., 'testphp.vulnweb.com' or 'scanme.nmap.org') or type 'exit' to quit."
    )

    try:
        while True:
            # Handle agent response / request for input from previous turn
            if current_pentest_state_dict.get("requires_user_input_for_tool"):
                tool_waiting_for = current_pentest_state_dict[
                    "requires_user_input_for_tool"
                ]
                user_guidance_prompt = "Guidance not found."
                # Find the last AI message which should contain the prompt
                for msg in reversed(current_pentest_state_dict["messages"]):
                    if isinstance(msg, AIMessage) and not getattr(
                        msg, "tool_calls", None
                    ):  # Ensure it's a textual response
                        user_guidance_prompt = msg.content
                        break

                print(
                    f"\n>>> AGENT (awaiting input for {tool_waiting_for}):\n{user_guidance_prompt}"
                )
                human_input = input(
                    f"\n[User {USER_ID} - Input for {tool_waiting_for}] >>> "
                )
            elif current_pentest_state_dict.get("current_phase") == "completed":
                print("\n>>> AGENT: Penetration test session completed.")
                final_report_msg = current_pentest_state_dict.get(
                    "report_data_summary", "No final report summary in state."
                )
                # Also check last message for report if generate_report_node was hit
                if (
                    isinstance(current_pentest_state_dict["messages"][-1], AIMessage)
                    and "Penetration Test Summary Report"
                    in current_pentest_state_dict["messages"][-1].content
                ):
                    final_report_msg = current_pentest_state_dict["messages"][
                        -1
                    ].content
                print(final_report_msg)
                break
            else:  # General interaction or if agent just gave a text response
                # Display last AI text response if any (that wasn't a tool call guidance)
                last_ai_msg_content = None
                if current_pentest_state_dict["messages"]:
                    for msg_idx in range(
                        len(current_pentest_state_dict["messages"]) - 1, -1, -1
                    ):
                        msg = current_pentest_state_dict["messages"][msg_idx]
                        if (
                            isinstance(msg, AIMessage)
                            and not getattr(msg, "tool_calls", None)
                            and not "USER_GUIDANCE_PROVIDED_FOR" in msg.content
                        ):
                            # Avoid re-printing ZAP/Metasploit guidance if it was the last thing
                            if not (
                                current_pentest_state_dict.get(
                                    "requires_user_input_for_tool"
                                )
                                and msg.content.startswith("USER ACTION REQUIRED")
                            ):
                                last_ai_msg_content = msg.content
                                break
                        elif isinstance(
                            msg, HumanMessage
                        ):  # Stop if we hit a human message first
                            break

                if last_ai_msg_content:
                    print(f"\n>>> AGENT:\n{last_ai_msg_content}")

                # Always prompt for user input after a text response in interactive_guidance
                if (
                    current_pentest_state_dict.get("current_phase")
                    == "interactive_guidance"
                ):
                    human_input = input(f"\n[User {USER_ID}] >>> ")
                else:
                    # For other phases, keep previous logic
                    human_input = input(f"\n[User {USER_ID}] >>> ")

            if human_input.lower() == "exit":
                print("Exiting...")
                # Optionally, inform the agent to wrap up
                current_pentest_state_dict["messages"] = add_messages(
                    current_pentest_state_dict["messages"],
                    [HumanMessage(content="exit")],
                )
                # Allow one more run for the agent to process "exit" and go to "SESSION_END"
                # then the loop will break due to "completed" phase.
            else:
                current_pentest_state_dict["messages"] = add_messages(
                    current_pentest_state_dict["messages"],
                    [HumanMessage(content=human_input)],
                )

            # Invoke the agent graph for one cycle of processing
            # The graph will run until it hits an END, or naturally completes a path for this turn.
            # For interactive CLI, we stream and take the final state of the stream.

            next_state_dict = None
            logger.info(
                f"Invoking agent with phase: {current_pentest_state_dict['current_phase']}"
            )
            # print(f"DEBUG: State before invoke: Messages: {[m.content[:50] for m in current_pentest_state_dict['messages']]}")

            for update_chunk in agent.agent_runnable.stream(
                current_pentest_state_dict, {"recursion_limit": 100}
            ):
                # `update_chunk` is a dictionary where keys are node names and values are the state *after* that node executed.
                # We want the state from the last executed node in this stream part.
                node_name = list(update_chunk.keys())[0]
                next_state_dict = update_chunk[node_name]  # This is the full state dict
                # logger.debug(f"Streamed from node: {node_name}, Phase: {next_state_dict.get('current_phase')}, ReqInput: {next_state_dict.get('requires_user_input_for_tool')}")
                # If the graph reaches END, or a node sets a condition for stopping this turn (like requires_user_input)
                if (
                    node_name == END
                    or next_state_dict.get("current_phase") == "completed"
                    or next_state_dict.get("requires_user_input_for_tool")
                ):
                    break

            if next_state_dict is None:  # Should not happen if graph runs
                logger.error("Agent did not return a state. Exiting.")
                break

            current_pentest_state_dict = (
                next_state_dict  # Update state for the next loop iteration
            )

            if (
                human_input.lower() == "exit"
                and current_pentest_state_dict.get("current_phase") == "completed"
            ):
                # If user typed exit and agent processed it to completion, print final agent message and break.
                if current_pentest_state_dict["messages"] and isinstance(
                    current_pentest_state_dict["messages"][-1], AIMessage
                ):
                    print(
                        f"\n>>> AGENT:\n{current_pentest_state_dict['messages'][-1].content}"
                    )
                break

    except KeyboardInterrupt:
        print("\nUser interrupted. Exiting...")
    finally:
        print("Pentest session ended.")
