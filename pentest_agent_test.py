# import webtech

# # you can use options, same as from the command line
# wt = webtech.WebTech(options={'json': True})

# # scan a single website
# try:
#   report = wt.start_from_url('http://ffuf.me/wordlists')
#   print(report)
# except webtech.utils.ConnectionException:
#   print("Connection error")

from googlesearch import search
import requests
from bs4 import BeautifulSoup


def google_scrape(url):
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")
    if soup is None or soup.title is None or soup.title.text is None:
        return "No title found"
    return soup.title.text


def web_exploit_search_tool(search_term: str) -> str:
    """
    Searches the web using Google for exploits and security information related to the search term.
    Input should be a specific search query, e.g., 'Grafana V11 CVE github poc' or 'WordPress File Upload Vulnerability CVE'.
    Returns a list of page titles and urls from the search results.
    """
    print(f"Web searching for exploits: {search_term}")
    results = []
    for i, url in enumerate(search(search_term)):
        a = google_scrape(url)
        print(str(i) + ". " + a)
        print(url)
        print(" ")
        results.append(a)
    return results



web_exploit_search_tool("grafana v11 cve github poc")
